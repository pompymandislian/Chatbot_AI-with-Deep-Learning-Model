{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data json\n",
    "with open('intents.json') as content:\n",
    "    data = json.load(content)\n",
    "\n",
    "# Load words \n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "\n",
    "# Load classes\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "\n",
    "# Load model\n",
    "model = load_model('D:/Project_Data/project/Project Pribadi/Chatbot Website/Code baru/chatbot_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_classes(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes and stems the input sentence using Sastrawi stemmer.\n",
    "\n",
    "    Args:\n",
    "    sentence (str): Input sentence to be tokenized and stemmed.\n",
    "\n",
    "    Returns:\n",
    "    list: List of tokenized and stemmed words.\n",
    "    \"\"\"\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    \"\"\"\n",
    "    Converts a sentence into a bag-of-words representation based on the loaded vocabulary.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Input sentence to be converted.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Bag-of-words representation of the input sentence.\n",
    "    \"\"\"\n",
    "    # Tokenize and stem the input sentence\n",
    "    sentence_words = clean_up_classes(sentence)\n",
    "    \n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence):\n",
    "    \"\"\"\n",
    "    Predicts the intent class of the input sentence using the loaded model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence : str \n",
    "        Input sentence for intent prediction.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list: \n",
    "        List of dictionaries containing the predicted intent and its probability.\n",
    "    \"\"\"\n",
    "    sentence_words = clean_up_classes(sentence)\n",
    "\n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence):\n",
    "    \"\"\"\n",
    "    Predicts the intent class of the input sentence using the loaded model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence : str \n",
    "        Input sentence for intent prediction.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list: \n",
    "        List of dictionaries containing the predicted intent and its probability.\n",
    "    \"\"\"\n",
    "    # Convert the sentence into a bag-of-words representation\n",
    "    bow = bag_of_words(sentence)\n",
    "\n",
    "    # Make a prediction using the loaded model\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    \n",
    "    # Apply a threshold to filter out predictions with low probabilities\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(intents_list, intents_json):\n",
    "    \"\"\"\n",
    "    Retrieves a random response for the predicted intent from the loaded data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    intents_list : list \n",
    "        List of dictionaries containing the predicted intent and its probability.\n",
    "    intents_json : dict \n",
    "        Dictionary containing the intent data loaded from the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str: \n",
    "        Randomly selected response for the predicted intent.\n",
    "    \"\"\"\n",
    "    # If intents_list is empty, set a default response\n",
    "    if not intents_list:\n",
    "        return \"Maaf, saya tidak mengerti pertanyaan Anda.\"\n",
    "\n",
    "    # Extract the predicted intent\n",
    "    tag = intents_list[0]['intent']\n",
    "    \n",
    "    # Find the intent with matching tag\n",
    "    matching_intent = next((intent for intent in intents_json['intents'] if intent['tag'] == tag), None)\n",
    "\n",
    "    # If matching intent is found, choose a random response\n",
    "    if matching_intent:\n",
    "        result = random.choice(matching_intent['responses'])\n",
    "    else:\n",
    "        # If no matching intent is found, set a default response\n",
    "        result = \"Maaf, saya tidak mengerti pertanyaan Anda.\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo Bot Zen akan membantu Anda\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Bot: Hi Tuan\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Bot: PT. Zenithera Kreasi adalah startup riset dan konsultasi yang berfokus pada data dan teknologi luas. Didirikan sebagai ZENITH pada tahun 2023, kami memiliki beberapa layanan business-to-business (B2B) business to Government (B2G), di bidang: Business dan Data\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Bot: Maaf, saya tidak mengerti pertanyaan Anda.\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hallo Bot Zen akan membantu Anda\")\n",
    "\n",
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if message.lower() == 'exit':\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    ints = predict_class(message)\n",
    "    res = get_response(ints, data)\n",
    "    print(\"Bot:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
